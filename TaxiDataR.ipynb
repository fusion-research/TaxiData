{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting and smoothing taxi data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "I chose to analyze the T-Drive trajectory data sample (https://www.microsoft.com/en-us/research/publication/t-drive-trajectory-data-sample/). This dataset contains the GPS trajectories for taxis in the Beijing area from February 2, 2008, to February 8, 2008<sup>1,2</sup>. \n",
    "\n",
    "The first part of the task was to produce the first two figures from the document summarizing the dataset (User_guide_T-drive.pdf) found at the site above.  The figures show histograms of the distance and time intervals between two consecutive points). The second part of the task was to present a smoothed trajectory using spline or Kalman filters of one of the taxis.\n",
    "\n",
    "The dataset can be found at the above site (under the tag \"Related Info\") as 9 zipped files (\"06\",\"07\",\"08\",\"09\",\"010\",\"011\",\"012\",\"013\",\"014\").  Each zipped file contains approximately 1000 txt files named as  taxi_id.txt, where taxi_id is a number identification from 1 to 10357. The file format (for each line) is:<br>\n",
    "taxi id, date time, longitude, latitude<br>\n",
    "separated by commas.\n",
    "\n",
    "The code is written in R.\n",
    "\n",
    "### References\n",
    "\n",
    "[1] Jing Yuan, Yu Zheng, Xing Xie, and Guangzhong Sun. Driving with knowledge from the physical world. In The 17th ACM SIGKDD international conference on Knowledge Discovery and Data mining, KDD’11, New York, NY, USA, 2011. ACM.<br>\n",
    "[2] Jing Yuan, Yu Zheng, Chengyang Zhang, Wenlei Xie, Xing Xie, Guangzhong Sun, and Yan Huang. T-drive: driving directions based on taxi trajectories. In Proceedings of the 18th SIGSPATIAL International Conference on Advances in Geographic Information Systems, GIS ’10, pages 99-108, New York, NY, USA,2010. ACM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getfilenames.R\n",
    "\n",
    "The 9 zipped files were downloaded to the home directory and unzipped, creating 9 subdirectories: \"06\",\"07\",\"08\",\"09\",\"010\",\"011\",\"012\",\"013\",\"014\". These names were put in the vector *indir*.\n",
    "\n",
    "This code goes through each directory and creates a dataframe *filelist* with 2 columns (for all the files in all the subdirectories). <br>\n",
    "Column 1: an index (1-9) into the vector indir to access the the subdirectory name <br>\n",
    "Column 2: the file name.<br>\n",
    "\n",
    "*l* is a temporary dataframe holding the index and the file names for the subdirectory in the loop.<br>\n",
    "\n",
    "Note that running this code found 8911 unique files across the dataset. This value is different than the value given in the documentation for this dataset (User_guide_T-drive.pdf), which listed 10,357 files (\"10357\" was the last taxi_id found)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getfilenames.R\n",
    "\n",
    "#home <- \"C:/Users/ibshi/Desktop/startup.ml/taxi\"\n",
    "home <- \"C:/Users/Steve S/Desktop/startup.ml/taxi\"\n",
    "setwd(home)\n",
    "\n",
    "indir <- c(\"06\",\"07\",\"08\",\"09\",\"010\",\"011\",\"012\",\"013\",\"014\")\n",
    "num_indir <- length(indir)\n",
    "\n",
    "# loop through each subdirectory\n",
    "\n",
    "for (i in 1:num_indir) { \n",
    "\n",
    "    # temp holds the subdirectory name\n",
    "    temp <- paste(home, indir[i], sep=\"/\")\n",
    "    \n",
    "    # put file names into l\n",
    "    l <- list.files(path=temp)\n",
    "    \n",
    "    # add an index for the subdirectory name vector indir to l\n",
    "    index <- c(rep.int(i,length(l)))\n",
    "    l <- cbind(index,l)\n",
    "    \n",
    "    # add l to filelist\n",
    "    if (i == 1) {\n",
    "        filelist <- l\n",
    "    } \n",
    "    else {\n",
    "      filelist <- rbind(filelist,l)\n",
    "    }\n",
    "    \n",
    "} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## readfiles.R\n",
    "\n",
    "This code goes through the dataframe *filelist*, reads in the txt files with read.csv(), and creates then appends a dataframe *taxi_data* with the columns listed above <br>\n",
    "taxi_id, date_time, longitude, latitude<br>\n",
    "\n",
    "To handle any empty files, a tryCatch statement sets *t* to either the new data read in, or to a null dataframe *s*.\n",
    "\n",
    "Also, a column was added, begin, which indicated the beginning of a new taxi_id, coded as 1/0 (yes/no), giving a final format for *taxi_data* of<br>\n",
    "taxi_id, date_time, longitude, latitude, begin<br>\n",
    "The begin column was added so that the distance and time intervals could be calcuated across all rows of *taxi_data* first, followed by setting interval values to NA for the beginning of a new taxi id. \n",
    "\n",
    "Each file was first read into a temporary dataframe *t*, which was then appended to *taxi_data*.\n",
    "\n",
    "Note that readfiles.R took about 11 hours to run on a standard PC laptop (Intel Core i7-6700, 2.6 GHz, 8G RAM).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# readfiles.R\n",
    "\n",
    "num_files <- nrow(filelist)\n",
    "#num_files <- 100 # to test code for subsequent steps\n",
    "print(paste(\"num_files = \",as.character(num_files)))\n",
    "\n",
    "# s is a null dataframe for read.csv() failures\n",
    "s <- data.frame(NULL,NULL,NULL,NULL)    \n",
    "\n",
    "# give s column names that match a successful read.csv() result\n",
    "s <- colnames(c(\"V1\",\"V2\",\"V3\",\"V4\")) \n",
    "\n",
    "# loop through filelist to read data into taxi_data\n",
    "\n",
    "for (j in 1:num_files) {\n",
    "\n",
    "  # tempname is the full name of a txt file\n",
    "\n",
    "  t_ind <- as.integer(filelist[j,1]) \n",
    "  tempname <- paste(home,indir[t_ind],filelist[j,2],sep=\"/\") \n",
    "\n",
    "  # a tryCatch that returns a temporary dataframe t with data from the tempdata file, or a null s dataframe\n",
    "\n",
    "  t <- tryCatch(read.csv(tempname, header = FALSE),error = function(e) {print(paste(\"error retrieving\",tempname));return(s);})\n",
    "\n",
    "  # conditional upon t$V1[1] not being null, 2 steps were done: \n",
    "  # 1. add begin column to t to indicate a new taxi_id \n",
    "  # 2. add t to taxi_data  \n",
    "\n",
    "  if (!is.null(t$V1[1])) { \n",
    "  \n",
    "      # 1. add begin column to t to indicate a new taxi_id \n",
    "      \n",
    "      t_len <- nrow(t)                \n",
    "      t_begin <- c(rep(0,t_len))\n",
    "      t_begin[1] <- 1\n",
    "      t_begin <- as.factor(t_begin)\n",
    "      t <- cbind(t,t_begin)   \n",
    "      \n",
    "      # 2. add t to taxi_data\n",
    "      \n",
    "      if (j == 1) {\n",
    "        taxi_data <- t\n",
    "      } \n",
    "      else {\n",
    "        taxi_data <- rbind(taxi_data,t)\n",
    "      }\n",
    "  }\n",
    "\n",
    "} \n",
    "\n",
    "colnames(taxi_data) <- c(\"taxi_id\",\"date_time\",\"longitude\",\"latitude\",\"begin\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of readfiles.R\n",
    "\n",
    "As stated above, readfiles.R took about 11 hours to run on a standard laptop. The output of the above code was: \n",
    "\n",
    "\"num_files =  8911\"<br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/10115.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/10352.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/1089.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/1497.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/1947.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/2929.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/2945.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/295.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/3050.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/3160.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/3194.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/3950.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/5972.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/6030.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/6236.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/6322.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/6717.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/7583.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/8209.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/8424.txt\" <br>\n",
    "[1] \"error retrieving C:/Users/ibshi/Desktop/startup.ml/taxi/014/9874.txt\" <br>\n",
    "\n",
    "Thus, 21 files had read errors (due to empty files), and the final count of files was 8911 - 21 = 8890.<br>\n",
    "The total number of rows for taxi_data points was 10,088,351, which is about 2/3 of the number stated in User_guide_T-drive.pdf (15 million).<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intervals.R\n",
    "\n",
    "This code adds a column interval_sec to *taxi_data* using the lubridate package. The steps are:<br>\n",
    "1. add a column to taxi_data (new_date_time) converting the input date_time column to POSIXct format<br> \n",
    "2. add a column to taxi_data (new_date_time_m1) with the new_date_time of the previous row<br>\n",
    "3. add a column to taxi_data (interval_sec) with the duration (in seconds) of the interval between new_date_time and new_date_time_m1. This was done across all rows; thus, the \"interval\" for the beginning of a new taxi_id is incorrect.<br>\n",
    "4. set interval_sec for the beginning of a new taxi_id to NA.<br>\n",
    "5. Drop the date_time and new_date_time_m1 columns (to save on RAM).<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# intervals.R\n",
    "\n",
    "library(lubridate)\n",
    "\n",
    "# add a column (new_date_time), converting the input date_time column to POSIXct date time format\n",
    "taxi_data$new_date_time <- ymd_hms(taxi_data$date_time)\n",
    "\n",
    "# add a column (new_date_time_m1) with the new_date_time of the previous row \n",
    "num_datam1 <- nrow(taxi_data) - 1\n",
    "t <- taxi_data$new_date_time[1:num_datam1]\n",
    "t <- c(t[1],t)\n",
    "taxi_data$new_date_time_m1 <- t\n",
    "rm(t)\n",
    "\n",
    "# add a column to taxi_data (interval_sec) with the duration (in seconds) of the interval between \n",
    "# new_date_time and new_date_time_m1. \n",
    "taxi_data$interval_sec <- as.duration(interval(taxi_data$new_date_time_m1,taxi_data$new_date_time))\n",
    "\n",
    "# set interval_sec for the beginning of a new taxi_id to NA\n",
    "taxi_data$interval_sec[which(taxi_data$begin == 1)] <- NA\n",
    "\n",
    "# Drop the date_time and new_date_time_m1 columns\n",
    "taxi_data <- subset.data.frame(taxi_data,select = c(\"taxi_id\",\"longitude\",\"latitude\",\"begin\",\"new_date_time\",\"interval_sec\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lat_long_conv.R\n",
    "\n",
    "This code first find the differences between adjacent times in latitude and longitude, and then converts this difference into distance, in meters.\n",
    "\n",
    "1. Add columns lat_m1 and long_m1 to *taxi_data* for the latitudes and longitudes of the previous rows. <br>\n",
    "2. Add columns diff_lat, diff_long, and ave_lat to *taxi_data* using latitude, lat_m1, longitude, and long_m1 <br>\n",
    "3. remove intermediary columns lat_m1 and long_m1 from *taxi_data* <br>\n",
    "4. Convert differences in latitude and longitude to distances in meters. This section uses the equations used by, for example: \n",
    "http://www.csgnetwork.com/degreelenllavcalc.html, which is referenced in Wikipedia (https://en.wikipedia.org/wiki/Geographic_coordinate_system), and is apparently accurate to 1 cm per degree latitude/longitude.<br>\n",
    "  a. Add columns lat_meters_per_1deg and lat_meters_per_1deg to *taxi_data* computing the length of 1 degree latitude and  longitude for the average latitude between 2 adjacent points <br>\n",
    "  b. Convert columns diff_lat and diff_long to meters <br>\n",
    "  c. Add column distance (in meters) to *taxi_data* by computing Euclidean distance from columns diff_lat and diff_long <br>\n",
    "  d. Set distance for the beginning of a new taxi_id to NA <br>\n",
    "  e. Remove intermediary columns diff_lat and diff_long from  from *taxi_data* <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lat_long_conv.R\n",
    "\n",
    "# Add columns lat_m1 and long_m1 to *taxi_data* for the latitudes and longitudes of the previous rows.\n",
    "\n",
    "num_datam1 <- nrow(taxi_data) - 1\n",
    "t <- taxi_data$latitude[1:num_datam1]\n",
    "t <- c(t[1],t)\n",
    "taxi_data$lat_m1 <- t\n",
    "\n",
    "t <- taxi_data$longitude[1:num_datam1]\n",
    "t <- c(t[1],t)\n",
    "taxi_data$long_m1 <- t\n",
    "\n",
    "rm(t)\n",
    "\n",
    "# Add columns diff_lat, diff_long, and ave_lat to *taxi_data* using latitude, lat_m1, longitude, and long_m1 \n",
    "\n",
    "taxi_data$diff_lat <- abs(taxi_data$latitude - taxi_data$lat_m1)\n",
    "taxi_data$diff_long <- abs(taxi_data$longitude - taxi_data$long_m1)\n",
    "taxi_data$ave_lat <- (taxi_data$latitude + taxi_data$lat_m1)/2\n",
    "\n",
    "# remove intermediary columns lat_m1 and long_m1 \n",
    "\n",
    "taxi_data <- subset.data.frame(taxi_data,select = c(\"taxi_id\",\"longitude\",\"latitude\",\"begin\",\"new_date_time\",\"interval_sec\",\"diff_lat\",\"diff_long\",\"ave_lat\"))\n",
    "\n",
    "# Convert differences in latitude and longitude to distances in meters. \n",
    "\n",
    "# this section uses the equations used by, for example:\n",
    "# http://www.csgnetwork.com/degreelenllavcalc.html,\n",
    "# which is referenced in Wikipedia (https://en.wikipedia.org/wiki/Geographic_coordinate_system),\n",
    "# and is apparently accurate to 1 cm per degree latitude/longitude\n",
    "\n",
    "m1 <- 111132.92     # latitude calculation term 1\n",
    "m2 <- -559.82       # latitude calculation term 2\n",
    "m3 <- 1.175         # latitude calculation term 3\n",
    "m4 <- -0.0023       # latitude calculation term 4\n",
    "p1 <- 111412.84     # longitude calculation term 1\n",
    "p2 <- -93.5         # longitude calculation term 2\n",
    "p3 <- -0.118         # longitude calculation term 3\n",
    "\n",
    "  # Add columns lat_meters_per_1deg and lat_meters_per_1deg to *taxi_data* computing the length of 1 degree latitude \n",
    "  # and longitude for the average latitude between 2 adjacent points (using the equations and parameters above)\n",
    "\n",
    "  taxi_data$lat_meters_per_1deg <- m1 + m2 * cos(2 * taxi_data$ave_lat*pi/180) + m3 * cos(4 * taxi_data$ave_lat*pi/180) + m4 * cos(6 * taxi_data$ave_lat*pi/180)\n",
    "  taxi_data$long_meters_per_1deg <- p1 * cos(taxi_data$ave_lat*pi/180) + p2 * cos(3 * taxi_data$ave_lat*pi/180) + p3 * cos(5 * taxi_data$ave_lat*pi/180)\n",
    "\n",
    "  # convert diff_lat and diff_long from degrees to meters\n",
    "\n",
    "  taxi_data$diff_long <- taxi_data$diff_long*taxi_data$long_meters_per_1deg\n",
    "  taxi_data$diff_lat <- taxi_data$diff_lat*taxi_data$lat_meters_per_1deg\n",
    "\n",
    "  # remove intermediary columns ave_lat, lat_meters_per_1deg, and long_meters_per_1deg \n",
    "\n",
    "  taxi_data <- subset.data.frame(taxi_data,select = c(\"taxi_id\",\"longitude\",\"latitude\",\"begin\",\"new_date_time\",\"interval_sec\",\"diff_lat\",\"diff_long\"))\n",
    "\n",
    "  # Add column distance (in meters) to *taxi_data* by computing Euclidean distance from columns diff_lat and diff_long\n",
    "\n",
    "  taxi_data$distance <- sqrt(taxi_data$diff_lat^2 + taxi_data$diff_long^2)\n",
    "\n",
    "  # set distance for the beginning of a new taxi_id to NA\n",
    "\n",
    "  taxi_data$distance[which(taxi_data$begin == 1)] <- NA\n",
    "\n",
    "  # remove intermediary columns diff_lat and diff_long \n",
    "\n",
    "  taxi_data <- subset.data.frame(taxi_data,select = c(\"taxi_id\",\"longitude\",\"latitude\",\"begin\",\"new_date_time\",\"interval_sec\",\"distance\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## figure_dist.R, figure_time.R\n",
    "\n",
    "This code uses the base R plotting to create the distance and time histograms. \n",
    "\n",
    "Note that there were data points beyond the range of the figures (>8000 for distance, >12 for time). These were included in the proportions, even though they were outside the range of the figures. I chose to do this, as I believe this is a more faithful representation of the data.\n",
    "\n",
    "### figure_dist.R\n",
    "\n",
    "The steps for figure_distance.R are:\n",
    "\n",
    "1. Count the number of rows with distance > 8000 (over_8000). \n",
    "2. In *t* (a temporary vector equal to taxi_data$distance), set those over_8000 to NA.\n",
    "3. Draw a density plot (h) to stdout. \n",
    "4. The plot h is converted to proportions with the count for over_8000 included, so that the proportions represent those over all the data (including those above 8000).\n",
    "5. The plot is written to distance.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# figure_dist.R\n",
    "\n",
    "# Count the number of rows with distance > 8000 (over_8000).\n",
    "over_8000 <- length(which(taxi_data$distance>8000))\n",
    "\n",
    "# In t (a temporary vector equal to taxi_data$distance), set those over_8000 to NA. \n",
    "t <- taxi_data$distance\n",
    "t[which(t>8000)] <- NA\n",
    "\n",
    "# Draw a density plot (h) to stdout.\n",
    "h <- hist(t,xlim=c(0,8000),freq=FALSE,breaks =c(seq(0,8000,by =500)))\n",
    "\n",
    "# The plot h is converted to proportions with the count for over_8000 included, so that the proportions represent \n",
    "# those over all the data (including those above 8000).\n",
    "h$counts <- h$counts/(sum(h$counts) + over_8000)\n",
    "\n",
    "# The plot is written to distance.pdf\n",
    "pdf(file =\"distance.pdf\")\n",
    "plot(h,xlab = \"distance interval (meters)\",ylab = \"proportion\",main=\"\", col = 34,xaxp  = c(0, 8000, 8),yaxp = c(0,.7,7),tck = 0.01)\n",
    "dev.off()\n",
    "rm(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure_time.R\n",
    "\n",
    "figure_time.R is similar in construction to figure_distance.R\n",
    "\n",
    "The steps for figure_time.R are:\n",
    "\n",
    "1. Set *t* (a temporary vector) equal to taxi_data$interval_sec\n",
    "2. Convert intervals from sec to min\n",
    "3. Count the number of rows with interval > 12 min \n",
    "4. Set the values over_12 to NA.\n",
    "5. Draw a density plot (h) to stdout. \n",
    "5. The plot h is converted to proportions with the count for over_12 included, so that the proportions represent those over all the data (including those above 12).\n",
    "5. The plot is written to time.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# figure_time.R\n",
    "\n",
    "# Set *t* (a temporary vector) equal to taxi_data$interval_sec\n",
    "t <- taxi_data$interval_sec\n",
    "\n",
    "# convert intervals from sec to min\n",
    "t <- as.single(t)/60\n",
    "\n",
    "# Count the number of rows with interval > 12 min \n",
    "over_12 <- length(which(t>12))\n",
    "\n",
    "# Set the values over 12 to NA.\n",
    "t[which(t>12)] <- NA\n",
    "\n",
    "# Draw a density plot (h) to stdout. \n",
    "h <- hist(t,xlim=c(0,12),freq=FALSE,breaks =c(seq(0,12,by =0.5)))\n",
    "\n",
    "# The plot h is converted to proportions with the count for over_12 included, \n",
    "# so that the proportions represent those over all the data (including those above 12).\n",
    "h$counts <- h$counts/(sum(h$counts) + over_12)\n",
    "\n",
    "# The plot is written to time.pdf.\n",
    "pdf(file =\"time.pdf\")\n",
    "plot(h,xlab = \"time interval (minutes)\",ylab = \"proportion\",main=\"\", col = 34,xaxp  = c(0, 12, 6),yaxp =c(0,.4,8),tck = 0.01)\n",
    "dev.off()\n",
    "rm(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance and time figure results\n",
    "\n",
    "Here is the resulting figure (distance.pdf) from figure_distance.R, and the resulting figure (time.pdf) from figure_time.R:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(\"IRdisplay\")\n",
    "home <- \"C:/Users/Steve S/Desktop/startup.ml/taxi/\"\n",
    "display_pdf(file = paste(home,\"distance.pdf\",sep=\"\"))\n",
    "display_pdf(file = paste(home,\"time.pdf\",sep=\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are a few differences between these figures and the figures in User_guide_T-drive.pdf. \n",
    "\n",
    "First, the above figures use the default for the hist() function, with the range of each bar corresponding to the actual range of values binned for that bar (e.g, for distance, 0-500, 501-1000, etc.). However, the bars in User_guide_T-drive.pdf appears to be centered upon the endpoints of the range (e.g., for distance, 500, 1000, etc.), and the range of the bars (about 400) less than the range for each of the bins (i.e., 500). As the default more accurately represents the data, I chose to keep the default configuration.\n",
    "\n",
    "Second, while the patterns of data across the figures are similar, the values do not match exactly. This could be due to my use of the proportions over all the data, whereas the figures in the User Guide may have used the proportions for only the values within the range of the figures (e.g., for distance, <= 8000). In particular, the values are higher for the distance proportions in the User Guide. Also, there could be differences due to the use of different samples, with 8890 files and about 10 million data points available online and 10357 files and 15 million data points described in User_guide_T-drive.pdf. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spline.R\n",
    "\n",
    "This code calculates the smoothed latitude and longitude functions separately, both with respect to (wrt) time, using spline(). Three figures were created: <br>\n",
    "Smoothed Latitude wrt Time (smooth_lat.pdf) <br>\n",
    "Smoothed Longitude wrt Time (smooth_longt.pdf)<br>\n",
    "Smoothed Latitude vs. smoothed longitude ((smooth_lat_v_long.pdf) <br>\n",
    "\n",
    "The code was tested for the first 3 files listed in subdirectory \"06\", \"39.txt\", \"220.txt\", and \"234.txt\". Figures from \"220.txt\" are presented below.\n",
    "\n",
    "Two issues arose in preliminary assessment. First, there were a number of interval durations equal to zero; rows with zero interval durations were removed. The replacement latitude and longitude were the averages across the two rows with the same new_date_time. In practice this seems to make little difference, as inspection of the 3 files found that the latitudes and longitudes were the same across consecutive rows with the same new_date_time. \n",
    "\n",
    "Second, there appeared to be some outliers in terms of latitude and longitude. To determine outliers, I used the code written for lat_long_conv.R to create a function to calculate the speed (calc_spped) in meters per second for adjacent points in time. The code found the first instance of a speed above a threshold (mps_limit), removed that point, and then recalculated the speeds. The procedure continued until no rows existed with a speed above the threshold. I chose a relatively conservative (i.e., high) threshold (100 mps = 223.7 mph), as the noise associated with the interval and position values could not be determined.\n",
    "\n",
    "The steps for spline.R are:\n",
    "\n",
    "1.\tread.csv infile into dataframe *raw*\n",
    "2.\tadd column new_date_time to *raw*, converting input date_time to POSIXct\n",
    "3.\tadd column new_date_time_m1 to *raw*, with the new_date_time from the previous rows\n",
    "4.\tadd column interval_sec to *raw*, set first interval to NA\n",
    "5.\tset *filtered* dataframe equal to *raw*\n",
    "6.\ttake out the rows from *filtered* with durations equal to zero <br>\n",
    "    a.\tFor the rows one back from rows having an interval of zero, set the latitudes and longitudes equal to the average of the two rows <br>\n",
    "    b.\tremove the rows with interval_sec equal to 0 <br>\n",
    "7.\tremove outliers in speed (above mps_limit) from *filtered*\n",
    "    a.\tset the initial lat, long, int_sec values as input to calc_speed <br>\n",
    "    b.\tcalculate the first pass of calc_speed, adding column speed to filtered <br>\n",
    "    c.\tset *s* as a vector containing indices of rows with speeds above thresholds <br>\n",
    "    d.\twhile the length of s != 0 (while there are speeds above threshold) <br>\n",
    "            i.\tremove the first instance of speed above threshold\n",
    "            ii.\trecalculate speed \n",
    "            iii. re-set s as vector containing indices of rows with speeds above thresholds\n",
    "8.\tprint out number of points after each stage of filtering\n",
    "9.\tperform splines upon latitude and longitude (wrt new_date_time)\n",
    "10.\tplot smoothed_latitude wrt time\n",
    "11.\tplot smoothed_longitude wrt time\n",
    "12.\tplot smoothed Latitude vs. Longitude\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spline.R\n",
    "\n",
    "# calc_speed returns a vector of speeds in meters/sec.  is essentially the code for lat_long_conv.R, with an added \n",
    "# calculation for speed = abs(distance/time) \n",
    "\n",
    "calc_speed <- function(lat,long,int_sec) {\n",
    "  \n",
    "# add columns lat_m1 and long_m1 in dataframe tmp with the latitides and longitudes of the previous rows\n",
    "    \n",
    "  tmp <- data.frame(lat,long,int_sec)\n",
    "  np <- nrow(tmp)\n",
    "  t <- tmp$lat[1:(np - 1)]\n",
    "  t <- c(t[1],t)\n",
    "  tmp$lat_m1 <- t\n",
    "  \n",
    "  t <- tmp$long[1:(np - 1)]\n",
    "  t <- c(t[1],t)\n",
    "  tmp$long_m1 <- t\n",
    "\n",
    "# add columns to tmp for diff_lat, diff_long, and ave_lat\n",
    "  \n",
    "  tmp$diff_lat <- abs(tmp$lat - tmp$lat_m1)\n",
    "  tmp$diff_long <- abs(tmp$long - tmp$long_m1)\n",
    "  tmp$ave_lat <- (tmp$lat + tmp$lat_m1)/2\n",
    "  \n",
    "  # this section uses the equations used by, for example:\n",
    "  # http://www.csgnetwork.com/degreelenllavcalc.html\n",
    "  # which is referenced in Wikipedia (https://en.wikipedia.org/wiki/Geographic_coordinate_system)\n",
    "  # and is apparently accurate to 1 cm per degree latitude/longitude\n",
    "  \n",
    "  m1 <- 111132.92     # latitude calculation term 1\n",
    "  m2 <- -559.82       # latitude calculation term 2\n",
    "  m3 <- 1.175         # latitude calculation term 3\n",
    "  m4 <- -0.0023       # latitude calculation term 4\n",
    "  p1 <- 111412.84     # longitude calculation term 1\n",
    "  p2 <- -93.5         # longitude calculation term 2\n",
    "  p3 <- -0.118         # longitude calculation term 3\n",
    "  \n",
    "  # add columns lat_meters_per_1deg and long_meters_per_1deg to tmp \n",
    "  # these equations give the length of 1 deg (lat and long) in meters for a given latitude, using the ave of the latitudes\n",
    "  \n",
    "  tmp$lat_meters_per_1deg <- m1 + m2 * cos(2 * tmp$ave_lat*pi/180) + m3 * cos(4 * tmp$ave_lat*pi/180) + m4 * cos(6 * tmp$ave_lat*pi/180)\n",
    "  tmp$long_meters_per_1deg <- p1 * cos(tmp$ave_lat*pi/180) + p2 * cos(3 * tmp$ave_lat*pi/180) + p3 * cos(5 * tmp$ave_lat*pi/180)\n",
    "  \n",
    "  # now convert differences in degrees to meters\n",
    "  tmp$diff_long <- tmp$diff_long*tmp$long_meters_per_1deg\n",
    "  tmp$diff_lat <- tmp$diff_lat*tmp$lat_meters_per_1deg\n",
    "\n",
    "  # calculate Euclidean distance and speed, m/sec\n",
    "  tmp$distance <- sqrt(tmp$diff_lat^2 + tmp$diff_long^2)\n",
    "  tmp$speed <- abs(tmp$distance/as.numeric(tmp$int_sec))\n",
    "    \n",
    "  # return the vector for speed  \n",
    "  ret <- tmp$speed \n",
    "  return(ret)\n",
    "  \n",
    "}\n",
    "\n",
    "# beginning of spline \n",
    "\n",
    "library(lubridate)\n",
    "mps_limit <- 100\n",
    "\n",
    "#home <- \"C:/Users/ibshi/Desktop/startup.ml/taxi\"\n",
    "home <- \"C:/Users/Steve S/Desktop/startup.ml/taxi\"\n",
    "setwd(home)\n",
    "\n",
    "# read.csv infile into dataframe raw\n",
    "\n",
    "#infile <- \"/06/39.txt\"\n",
    "infile <- \"/06/220.txt\"\n",
    "#infile <- \"/06/234.txt\"\n",
    "infile <- paste(home, infile,sep=\"\")\n",
    "\n",
    "raw <- read.csv(infile, header = FALSE)\n",
    "colnames(raw) <- c(\"taxi_id\",\"date_time\",\"longitude\",\"latitude\")\n",
    "npoints_orig <- nrow(raw)\n",
    "\n",
    "# add column new_date_time to raw, converting input date_time to POSIXct\n",
    "\n",
    "raw$new_date_time <- ymd_hms(raw$date_time)\n",
    "\n",
    "# add column new_date_time_m1 to raw, with the new_date_time from the previous rows\n",
    "\n",
    "t <- raw$new_date_time[1:(npoints_orig-1)]\n",
    "t <- c(t[1],t)\n",
    "raw$new_date_time_m1 <- t\n",
    "\n",
    "# add column interval_sec to raw, set first interval to NA \n",
    "\n",
    "raw$interval_sec <- as.duration(interval(raw$new_date_time_m1,raw$new_date_time))\n",
    "raw$interval_sec[1] <- NA\n",
    "\n",
    "# set filtered dataframe equal to raw\n",
    "\n",
    "filtered <- raw\n",
    "\n",
    "# take out the rows with durations equal to zero\n",
    "\n",
    "  # For the rows one back from rows having an interval of zero, set the latitudes \n",
    "  # and longitudes equal to the average of the two rows\n",
    "\n",
    "for (k in 2:npoints_orig) {\n",
    "if (filtered$interval_sec[k] == as.duration(0)){\n",
    "  filtered$latitude[k-1] <- (filtered$latitude[k-1]+filtered$latitude[k])/2\n",
    "  filtered$longitude[k-1] <- (filtered$longitude[k-1]+filtered$longitude[k])/2\n",
    "  }\n",
    "}\n",
    "\n",
    "  # remove the rows with interval_sec equal to 0\n",
    "\n",
    "filtered <- filtered[which(filtered$interval_sec != as.duration(0)),]\n",
    "npoints_nozero <- nrow(filtered)\n",
    "\n",
    "# remove outliers in speed (above mps_limit)\n",
    "\n",
    "  # set the initial lat, long, int_sec values as input to calc_speed\n",
    "\n",
    "lat <- filtered$latitude\n",
    "long <- filtered$long\n",
    "int_sec <- filtered$interval_sec\n",
    " \n",
    "  # calculate the first pass of calc_speed, adding column speed to filtered\n",
    "\n",
    "filtered$speed <- calc_speed(lat, long, int_sec)\n",
    "\n",
    "  # set s as a vector containing indices of rows with speeds above thresholds\n",
    "\n",
    "s <- which(filtered$speed > mps_limit)\n",
    "\n",
    "  # while the length of s != 0 (while there are speeds above threshold)\n",
    "\n",
    "while (length(s) != 0) {\n",
    "\n",
    "  # remove the first instance of speed above threshold\n",
    "    \n",
    "  curr_ind <- s[1]\n",
    "  curr_nrow <- nrow(filtered) \n",
    "  filtered <- rbind(filtered[1:(curr_ind-1),],filtered[(curr_ind+1):curr_nrow,])\n",
    "\n",
    "   # recalculate speed \n",
    "    \n",
    "  lat <- filtered$latitude\n",
    "  long <- filtered$long\n",
    "  int_sec <- filtered$interval_sec\n",
    "  filtered$speed <- calc_speed(lat, long, int_sec)\n",
    "\n",
    "  # re-set s as vector containing indices of rows with speeds above thresholds\n",
    "    \n",
    "  s <- which(filtered$speed > mps_limit)\n",
    "\n",
    "}\n",
    "\n",
    "# print out number of points after each stage of filtering\n",
    "\n",
    "npoints <- nrow(filtered)\n",
    "print(paste(\"npoints orig\",as.character(npoints_orig)))\n",
    "print(paste(\"npoints no zeroes\",as.character(npoints_nozero)))\n",
    "print(paste(\"npoints removing high speeds\",as.character(npoints)))\n",
    "\n",
    "# perform splines upon latitude and longitude (wrt new_date_time)\n",
    "\n",
    "smoothed_lat  <- spline(filtered$new_date_time,filtered$latitude,n=length(filtered$new_date_time))\n",
    "smoothed_long <- spline(filtered$new_date_time,filtered$longitude,n=length(filtered$new_date_time))\n",
    "\n",
    "# plot smoothed_latitude wrt time\n",
    "\n",
    "pdf(file = \"smooth_lat.pdf\")\n",
    "plot(filtered$new_date_time,filtered$latitude,ylab = \"latitude\",xlab = \"time\",main=\"Smoothed Latitude wrt Time\")\n",
    "mtext(\"Points represent the raw data. Lines represent the smoothed spline trajectory.\",side = 3)\n",
    "lines(smoothed_lat$x,smoothed_lat$y)\n",
    "dev.off()\n",
    "\n",
    "# plot smoothed_longitude wrt time \n",
    "\n",
    "pdf(file = \"smooth_long.pdf\")\n",
    "plot(filtered$new_date_time,filtered$longitude,ylab = \"longitude\",xlab = \"time\",main=\"Smoothed Longitude wrt Time\")\n",
    "mtext(\"Points represent the raw data. Lines represent the smoothed spline trajectory.\",side = 3)\n",
    "lines(smoothed_long$x,smoothed_long$y)\n",
    "dev.off()\n",
    "\n",
    "# plot smoothed Latitude vs. Longitude\n",
    "\n",
    "pdf(file = \"smooth_lat_v_long.pdf\")\n",
    "plot(filtered$latitude,filtered$longitude,ylab = \"longitude\",xlab = \"latitude\",main = \"Smoothed Latitude and Longitude\")\n",
    "mtext(\"Points represent the raw data. Lines represent the smoothed spline trajectory.\",side = 3)\n",
    "lines(smoothed_lat$y,smoothed_long$y)\n",
    "dev.off()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## figures from spline.R\n",
    "\n",
    "Below are the results for \"~/06/220.txt\". For all figures, the points represent the raw data points, and the lines represent the smoothed trajectories.\n",
    "\n",
    "The output from spline.R was: <br>\n",
    "[1] \"npoints orig 1820\" <br>\n",
    "[1] \"npoints no zeroes 1746\" <br>\n",
    "[1] \"npoints removing high speeds 1744\" <br>\n",
    "Thus, there were 1820-1746=74 rows with interval duration = 0, and 2 rows with speeds above threshold ( 100 mps)\n",
    "\n",
    "Here is: <br>\n",
    "the figure for latitude with respect to (wrt) time (smooth_lat.pdf), <br>\n",
    "the figure for longitude with respect to (wrt) time (smooth_long.pdf), and <br>\n",
    "the figure for latitude vs. longitude (smooth_lat_v_long.pdf). <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(\"IRdisplay\")\n",
    "home <- \"C:/Users/Steve S/Desktop/startup.ml/taxi/\"\n",
    "display_pdf(file = paste(home,\"smooth_lat.pdf\",sep=\"\"))\n",
    "display_pdf(file = paste(home,\"smooth_long.pdf\",sep=\"\"))\n",
    "display_pdf(file = paste(home,\"smooth_lat_v_long.pdf\",sep=\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spline_display.R\n",
    "\n",
    "This code does essentially the same thing as spline.R, but displays the figures without saving to a file and waits for a user response. Also, this code displays figures using subsets of the data based upon a range of indices, called beg and end, starting with beg <- 1. In this code the size of the range is set to step_point <- 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spline_display.R\n",
    "\n",
    "# calc_speed returns a vector of speeds in meters/sec.  is essentially the code for lat_long_conv.R, with an added \n",
    "# calculation for speed = abs(distance/time) \n",
    "\n",
    "calc_speed <- function(lat,long,int_sec) {\n",
    "  \n",
    "# add columns lat_m1 and long_m1 in dataframe tmp with the latitides and longitudes of the previous rows\n",
    "    \n",
    "  tmp <- data.frame(lat,long,int_sec)\n",
    "  np <- nrow(tmp)\n",
    "  t <- tmp$lat[1:(np - 1)]\n",
    "  t <- c(t[1],t)\n",
    "  tmp$lat_m1 <- t\n",
    "  \n",
    "  t <- tmp$long[1:(np - 1)]\n",
    "  t <- c(t[1],t)\n",
    "  tmp$long_m1 <- t\n",
    "\n",
    "# add columns to tmp for diff_lat, diff_long, and ave_lat\n",
    "  \n",
    "  tmp$diff_lat <- abs(tmp$lat - tmp$lat_m1)\n",
    "  tmp$diff_long <- abs(tmp$long - tmp$long_m1)\n",
    "  tmp$ave_lat <- (tmp$lat + tmp$lat_m1)/2\n",
    "  \n",
    "  # this section uses the equations used by, for example:\n",
    "  # http://www.csgnetwork.com/degreelenllavcalc.html\n",
    "  # which is referenced in Wikipedia (https://en.wikipedia.org/wiki/Geographic_coordinate_system)\n",
    "  # and is apparently accurate to 1 cm per degree latitude/longitude\n",
    "  \n",
    "  m1 <- 111132.92     # latitude calculation term 1\n",
    "  m2 <- -559.82       # latitude calculation term 2\n",
    "  m3 <- 1.175         # latitude calculation term 3\n",
    "  m4 <- -0.0023       # latitude calculation term 4\n",
    "  p1 <- 111412.84     # longitude calculation term 1\n",
    "  p2 <- -93.5         # longitude calculation term 2\n",
    "  p3 <- -0.118         # longitude calculation term 3\n",
    "  \n",
    "  # add columns lat_meters_per_1deg and long_meters_per_1deg to tmp \n",
    "  # these equations give the length of 1 deg (lat and long) in meters for a given latitude, using the ave of the latitudes\n",
    "  \n",
    "  tmp$lat_meters_per_1deg <- m1 + m2 * cos(2 * tmp$ave_lat*pi/180) + m3 * cos(4 * tmp$ave_lat*pi/180) + m4 * cos(6 * tmp$ave_lat*pi/180)\n",
    "  tmp$long_meters_per_1deg <- p1 * cos(tmp$ave_lat*pi/180) + p2 * cos(3 * tmp$ave_lat*pi/180) + p3 * cos(5 * tmp$ave_lat*pi/180)\n",
    "  \n",
    "  # now convert differences in degrees to meters\n",
    "  tmp$diff_long <- tmp$diff_long*tmp$long_meters_per_1deg\n",
    "  tmp$diff_lat <- tmp$diff_lat*tmp$lat_meters_per_1deg\n",
    "\n",
    "  # calculate Euclidean distance and speed, m/sec\n",
    "  tmp$distance <- sqrt(tmp$diff_lat^2 + tmp$diff_long^2)\n",
    "  tmp$speed <- abs(tmp$distance/as.numeric(tmp$int_sec))\n",
    "    \n",
    "  # return the vector for speed  \n",
    "  ret <- tmp$speed \n",
    "  return(ret)\n",
    "  \n",
    "}\n",
    "\n",
    "# beginning of spline \n",
    "\n",
    "library(lubridate)\n",
    "mps_limit <- 100\n",
    "\n",
    "#home <- \"C:/Users/ibshi/Desktop/startup.ml/taxi\"\n",
    "home <- \"C:/Users/Steve S/Desktop/startup.ml/taxi\"\n",
    "setwd(home)\n",
    "\n",
    "# read.csv infile into dataframe raw\n",
    "\n",
    "#infile <- \"/06/39.txt\"\n",
    "infile <- \"/06/220.txt\"\n",
    "#infile <- \"/06/234.txt\"\n",
    "infile <- paste(home, infile,sep=\"\")\n",
    "\n",
    "raw <- read.csv(infile, header = FALSE)\n",
    "colnames(raw) <- c(\"taxi_id\",\"date_time\",\"longitude\",\"latitude\")\n",
    "npoints_orig <- nrow(raw)\n",
    "\n",
    "# add column new_date_time to raw, converting input date_time to POSIXct\n",
    "\n",
    "raw$new_date_time <- ymd_hms(raw$date_time)\n",
    "\n",
    "# add column new_date_time_m1 to raw, with the new_date_time from the previous rows\n",
    "\n",
    "t <- raw$new_date_time[1:(npoints_orig-1)]\n",
    "t <- c(t[1],t)\n",
    "raw$new_date_time_m1 <- t\n",
    "\n",
    "# add column interval_sec to raw, set first interval to NA \n",
    "\n",
    "raw$interval_sec <- as.duration(interval(raw$new_date_time_m1,raw$new_date_time))\n",
    "raw$interval_sec[1] <- NA\n",
    "\n",
    "# set filtered dataframe equal to raw\n",
    "\n",
    "filtered <- raw\n",
    "\n",
    "# take out the rows with durations equal to zero\n",
    "\n",
    "  # For the rows one back from rows having an interval of zero, set the latitudes \n",
    "  # and longitudes equal to the average of the two rows\n",
    "\n",
    "for (k in 2:npoints_orig) {\n",
    "if (filtered$interval_sec[k] == as.duration(0)){\n",
    "  filtered$latitude[k-1] <- (filtered$latitude[k-1]+filtered$latitude[k])/2\n",
    "  filtered$longitude[k-1] <- (filtered$longitude[k-1]+filtered$longitude[k])/2\n",
    "  }\n",
    "}\n",
    "\n",
    "  # remove the rows with interval_sec equal to 0\n",
    "\n",
    "filtered <- filtered[which(filtered$interval_sec != as.duration(0)),]\n",
    "npoints_nozero <- nrow(filtered)\n",
    "\n",
    "# remove outliers in speed (above mps_limit)\n",
    "\n",
    "  # set the initial lat, long, int_sec values as input to calc_speed\n",
    "\n",
    "lat <- filtered$latitude\n",
    "long <- filtered$long\n",
    "int_sec <- filtered$interval_sec\n",
    " \n",
    "  # calculate the first pass of calc_speed, adding column speed to filtered\n",
    "\n",
    "filtered$speed <- calc_speed(lat, long, int_sec)\n",
    "\n",
    "  # set s as a vector containing indices of rows with speeds above thresholds\n",
    "\n",
    "s <- which(filtered$speed > mps_limit)\n",
    "\n",
    "  # while the length of s != 0 (while there are speeds above threshold)\n",
    "\n",
    "while (length(s) != 0) {\n",
    "\n",
    "  # remove the first instance of speed above threshold\n",
    "    \n",
    "  curr_ind <- s[1]\n",
    "  curr_nrow <- nrow(filtered) \n",
    "  filtered <- rbind(filtered[1:(curr_ind-1),],filtered[(curr_ind+1):curr_nrow,])\n",
    "\n",
    "   # recalculate speed \n",
    "    \n",
    "  lat <- filtered$latitude\n",
    "  long <- filtered$long\n",
    "  int_sec <- filtered$interval_sec\n",
    "  filtered$speed <- calc_speed(lat, long, int_sec)\n",
    "\n",
    "  # re-set s as vector containing indices of rows with speeds above thresholds\n",
    "    \n",
    "  s <- which(filtered$speed > mps_limit)\n",
    "\n",
    "}\n",
    "\n",
    "# print out number of points after each stage of filtering\n",
    "\n",
    "npoints <- nrow(filtered)\n",
    "print(paste(\"npoints orig\",as.character(npoints_orig)))\n",
    "print(paste(\"npoints no zeroes\",as.character(npoints_nozero)))\n",
    "print(paste(\"npoints removing high speeds\",as.character(npoints)))\n",
    "\n",
    "# perform splines upon latitude and longitude (wrt new_date_time)\n",
    "\n",
    "smoothed_lat  <- spline(filtered$new_date_time,filtered$latitude,n=length(filtered$new_date_time))\n",
    "smoothed_long <- spline(filtered$new_date_time,filtered$longitude,n=length(filtered$new_date_time))\n",
    "\n",
    "step_point <- 400\n",
    "num_step <- as.integer(npoints/step_point)\n",
    "\n",
    "# plot smoothed_latitude wrt time\n",
    "\n",
    "plot(filtered$new_date_time,filtered$latitude,ylab = \"latitude\",xlab = \"time\",main=\"Smoothed Latitude wrt Time\")\n",
    "mtext(\"Points represent the raw data. Lines represent the smoothed spline trajectory.\",side = 3)\n",
    "lines(smoothed_lat$x,smoothed_lat$y)\n",
    "cat (\"Press [enter] to continue\")\n",
    "line <- readline()\n",
    "\n",
    "  # plot for ranges, starting with 1 and size of range equal to step_point\n",
    "\n",
    "for (i in 1:num_step) {\n",
    "  beg <- step_point*(i - 1)+ 1\n",
    "  end <- step_point*(i - 1) + step_point\n",
    "  temp_ti <- paste(\"Smoothed Latitude wrt Time, points\",as.character(beg),\"to \", as.character(end))\n",
    "  plot(filtered$new_date_time[beg:end],filtered$latitude[beg:end],ylab = \"latitude\",xlab = \"time\",main=temp_ti)\n",
    "  mtext(\"Points represent the raw data. Lines represent the smoothed spline trajectory.\",side = 3)\n",
    "  lines(smoothed_lat$x[beg:end],smoothed_lat$y[beg:end])\n",
    "  cat (\"Press [enter] to continue\")\n",
    "  line <- readline()\n",
    "}\n",
    "\n",
    "  # plot to the end of the data (npoints)\n",
    "\n",
    "beg <- step_point*num_step + 1\n",
    "end <- npoints\n",
    "temp_ti <- paste(\"Smoothed Latitude wrt Time, points\",as.character(beg),\"to \", as.character(end))\n",
    "plot(filtered$new_date_time[beg:end],filtered$latitude[beg:end],ylab = \"latitude\",xlab = \"time\",main=temp_ti)\n",
    "mtext(\"Points represent the raw data. Lines represent the smoothed spline trajectory.\",side = 3)\n",
    "lines(smoothed_lat$x[beg:end],smoothed_lat$y[beg:end])\n",
    "cat (\"Press [enter] to continue\")\n",
    "line <- readline()\n",
    "\n",
    "# plot smoothed_longitude wrt time \n",
    "\n",
    "plot(filtered$new_date_time,filtered$longitude,ylab = \"longitude\",xlab = \"time\",main=\"Smoothed Longitude wrt Time\")\n",
    "mtext(\"Points represent the raw data. Lines represent the smoothed spline trajectory.\",side = 3)\n",
    "lines(smoothed_long$x,smoothed_long$y)\n",
    "cat (\"Press [enter] to continue\")\n",
    "line <- readline()\n",
    "\n",
    "  # plot for ranges, starting with 1 and size of range equal to step_point\n",
    "\n",
    "for (i in 1:num_step) {\n",
    "    beg <- step_point*(i - 1)+ 1\n",
    "    end <- step_point*(i - 1) + step_point\n",
    "    temp_ti <- paste(\"Smoothed Longitude wrt Time, points\",as.character(beg),\"to \", as.character(end))\n",
    "    plot(filtered$new_date_time[beg:end],filtered$longitude[beg:end],ylab = \"longitude\",xlab = \"time\",main=temp_ti)\n",
    "    mtext(\"Points represent the raw data. Lines represent the smoothed spline trajectory.\",side = 3)\n",
    "    lines(smoothed_long$x[beg:end],smoothed_long$y[beg:end])\n",
    "    cat (\"Press [enter] to continue\")\n",
    "    line <- readline()\n",
    "}\n",
    "\n",
    "  # plot to the end of the data (npoints}\n",
    "\n",
    "beg <- step_point*num_step + 1\n",
    "end <- npoints\n",
    "temp_ti <- paste(\"Smoothed Longitude wrt Time, points\",as.character(beg),\"to \", as.character(end))\n",
    "plot(filtered$new_date_time[beg:end],filtered$longitude[beg:end],ylab = \"longitude\",xlab = \"time\",main=temp_ti)\n",
    "mtext(\"Points represent the raw data. Lines represent the smoothed spline trajectory.\",side = 3)\n",
    "lines(smoothed_long$x[beg:end],smoothed_long$y[beg:end])\n",
    "cat (\"Press [enter] to continue\")\n",
    "line <- readline()\n",
    "\n",
    "# plot smoothed Latitude vs. Longitude\n",
    "\n",
    "plot(filtered$latitude,filtered$longitude,ylab = \"longitude\",xlab = \"latitude\",main = \"Smoothed Latitude and Longitude\")\n",
    "mtext(\"Points represent the raw data. Lines represent the smoothed spline trajectory.\",side = 3)\n",
    "lines(smoothed_lat$y,smoothed_long$y)\n",
    "cat (\"Press [enter] to continue\")\n",
    "line <- readline()\n",
    "\n",
    "  # plot for ranges, starting with 1 and size of range equal to step_point\n",
    "\n",
    "for (i in 1:num_step) {\n",
    "    beg <- step_point*(i - 1)+ 1\n",
    "    end <- step_point*(i - 1) + step_point\n",
    "    temp_ti <- paste(\"Smoothed Latitude and Longitude, points\",as.character(beg),\"to \", as.character(end))\n",
    "    plot(filtered$latitude[beg:end],filtered$longitude[beg:end],ylab = \"longitude\",xlab = \"latitude\",main = temp_ti)\n",
    "    lines(smoothed_lat$y[beg:end],smoothed_long$y[beg:end])\n",
    "    cat (\"Press [enter] to continue\")\n",
    "    line <- readline()\n",
    "}\n",
    "\n",
    "  # plot to the end of the data (npoints}\n",
    "\n",
    "beg <- step_point*num_step + 1\n",
    "end <- npoints\n",
    "temp_ti <- paste(\"Smoothed Latitude and Longitude, points\",as.character(beg),\"to \", as.character(end))\n",
    "plot(filtered$latitude[beg:end],filtered$longitude[beg:end],ylab = \"longitude\",xlab = \"latitude\",main = temp_ti)\n",
    "lines(smoothed_lat$y[beg:end],smoothed_long$y[beg:end])\n",
    "cat (\"Press [enter] to continue\")\n",
    "line <- readline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
